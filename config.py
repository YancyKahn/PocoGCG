MODEL_PATH_AND_TEMPLATE = {
    "llama-2": {
        "path": "/root/LLM/llama-2-7b-chat",
        # "path": "meta-llama/Llama-2-7b-chat-hf",
        "template": "llama-2"
    },
    "vicuna": {
        "path": "/root/LLM/vicuna-7b-v1.5",
        # "path": "lmsys/vicuna-7b-v1.5",
        "template": "vicuna_v1.1"
    },
    "mistral": {
        "path": "/root/LLM/mistral",
        # "path": "mistralai/Mistral-7B-v0.1",
        "template": "mistral"
    },
    "llama-3": {
        "path": "/data01/LLM/Meta-Llama-3-8B-Instruct/models--meta-llama--Meta-Llama-3-8B-Instruct/snapshots/e1945c40cd546c78e41f1151f4db032b271faeaa",
        # "path": "meta-llama/Meta-Llama-3-8B-Instruct",
        "template": "llama-3"
    }
}

DATA_PATH = "/root/PocoGCG/data/test/data.csv"
